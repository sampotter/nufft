* Todo
** Immediate todo
   - [ ] Figure this bug out:
#+BEGIN_SRC:
K = 380
  method: irt, time: 0.0176377 (out of 100 trials)
  method: potts, time: 0.000340558 (out of 10 trials)
  method: greengard, time: 0.000290388 (out of 28 trials)
  method: nufft, time: 0.079888 (out of 14 trials)
Assertion failed: (*std::min_element(std::cbegin(X_per), std::cend(X_per)) >= 0), function compute_P, file ../../nufft.impl.hpp, line 140.
abort trap: 6
#+END_SRC
   - [ ] Generate plots using tikz
   - [ ] Add references in paper to other definitions (i.e. (38) in
     Fessler)
	 - [ ] Rewrite section to use IDFT consistent with (38)
   - [ ] Add reference to that sinc interpolation/bandlimited note!
   - [ ] elpy
   - [ ] Test [-N/2, ..., N/2) with [0, ..., N) but for my test funcs
   - [ ] Use -⌊K/2⌋, ..., ⌈K/2⌉ instead of
   - [ ] Move timer into C++ timer wrapper for timing NUFFT C++
** NUFFTs to add
   - [ ] The Julia NUFFT
   - [ ] The Airforce Research Lab (?) NUFFT
   - [ ] Are there any NUFFT packages on CRAN?
** NUFFT
   - [ ] Make Python NUFFT use complex numbers with its
     FMM... (weights and output values)
   - [ ] Add C++ NUFFT to nufft.py
   - [ ] Add least squares collocation to C++ NUFFT
   - [ ] Get C++ unit tests working
   - [ ] Add unit test for C++ NUFFT in nufft.py
   - [ ] Figure out what the invalid value in np.multiply is
   - [ ] Get FMM to use new c0 estimation method
   - [ ] Change least squares to upper triangular approach
** Plots
   - [ ] Plots comparing checkpoint methods
   - [ ] Time vs. problem size vs. method (fixed error)
   - [ ] Error vs. problem size vs. method (fixed time)
   - [ ] Time/error vs. problem size... where number of source/target
     points are alternatingly fixed
   - [ ] Correct digits vs. radians vs. method (fixed... what?)
** Analysis
   - [ ] Figure out optimal P-by-P fitting matrix for upper triangular
     approach using explicit forms that we have...
   - [ ] Figure out method of choosing correct FMM parameters
** Cauchy kernel stuff
   - [ ] Find paper Nail was talking about re: Chebyshev expansions
	 - [ ] Implement using C++ framework
   - [ ] Try applying Gram-Schmidt to 1/(x-y)
	 - [ ] Implement using C++ framework
   - [ ] See if there were other methods of representing the Cauchy
     kernel discussed in the slides in class
* NUFFT
** Stuff to Code
   - [ ] Forward transform.
   - [ ] Vandermonde inversion for collocation.
** Analysis
   - [ ] Compare methods of estimating c0.
   - [ ] Are any of the test functions more or less difficult to interpolate?
	 - [ ] What about adding test functions which are just random sums
       of sinusoids?
** Plots to Make
*** Comparison Plots
**** Problem Size vs. Time (to compute to some prescribed accuracy)
	 Things to compare:
	 - IFFT (baseline)
	 - INUFFT using just phifar (note how large it needs to be to
       achieve the required accuracy and if this changes depending on
       the problem size)
	 - INUFFT using phifar and phinear
	 - min/max INUFFT
	 Note: /since clang on OS X doesn't support OpenMP, parfor loops
	 are treated as for loops./
** Goals
   - Approximate good choices for:
	 + the FMM depth,
	 + the truncation number,
	 + the radial neighborhood size,
	 + and the number of checkpoint pairs,
	 based on:
	 + the bandlimit,
	 + the function evaluates,
	 + and the evaluation points.
** Things to Verify Using Plots
   - [ ] Increasing the size of the radial neighborhood, all else being
     equal, should improve the accuracy.
   - [ ] Different checkpoint methods should perform differently.
   - [ ] Increasing the truncation number should improve accuracy.
   - [ ] Increasing the FMM depth should decrease accuracy but improve
     speed.
   - [ ] With the rest of the parameters fixed, there should be an
     optimal FMM depth.
** Things to Read
   - [ ] [[https://en.wikipedia.org/wiki/Dirichlet_kernel][Wikipedia - Dirichlet kernel]]
   - [ ] "Multipole Expansions and Pseudospectral Cardinal Functions"
** Links
*** References
   	- [[http://fastmultipole.org/Main/T-NuFFT][site containing links and references to NuFFT implementations]]
*** NUFFT Implementations
   	- [[http://cs.nyu.edu/cs/faculty/berger/nufft/nufft.html][CMCL (Courant)]]
   	- [[https://www-user.tu-chemnitz.de/~potts/nfft/download.php][Potts (TU Chemnitz)]]
   	- [[http://www.mathworks.com/matlabcentral/fileexchange/25135-nufft--nfft--usfft][Matthew Ferrara (Air Force Research Laboratory)]]
   	- [[http://web.eecs.umich.edu/~fessler/code/index.html][Image reconstruction toolbox]]

* Cauchy Kernel FMM
** C++ Implementation
   - [ ] Replace ~std::vector~ with ~boost::numeric::ublas::vector~?
   - [ ] Figure out how to deal with domain and range types -- if this
	 is even necessary...
   - [X] Try out using Boost.Optional for the bookmarks instead of
	 using a pair of -1's to indicate no bookmark.
   - [ ] Alternative bookmark data structures to try:
	 - [ ] Heap-based
	 - [ ] Linear probing (i.e. no buckets) implementation
   - [ ] Play around with the ~inline~ keyword for optimization.
   - [ ] Factor out Kahan summation for reuse...
   - [ ] Kahan product?
   - [ ] Make ~p~ a template parameter to enable use of arrays on the
	 stack...
   - [ ] Look into Shewchuk summation...
*** Refactoring
	- [ ] There are a lot of loops involving indices compared to
      variables which are initially declared in the argument list of
      some function. It would be nice to be able to allow for
      arbitrary types for the indices, which will require those
      arguments to be of some template type, in which case we will
      need to go and replace a lot of things with auto and decltype,
      and MOST LIKELY provide some separate---conditionally
      compiled---sections of code for dealing with signed and unsigned
      cases...
*** Optimization
**** General
   	 - [ ] Put EVERYTHING on the stack/or preallocate all memory used
   	 - [ ] Remove dependance on boost (for compilation speed)
   	 - [ ] Diagram algorithm to try and figure out best way to move memory around
   	 - [ ] Sum directly into coefficient vectors instead of using an intermediate workspace
   	 - [ ] Don't use maps -- or at least don't use STL maps?
   	 - [ ] don't unnecessarily propagate coefficients that aren't there...
   	 - [ ] SSE/SIMD?
   	 - [ ] use a heap for the index finder?
**** Implementation-specific
	 - [ ] Coalesce X and X_per (i.e. X is contained in X_per, so it's
       redundant)
	 - [ ] Also redundant: computing X_per and then scaling X_per---we
       can compute it directly.
	 - [ ] Look into whether or not computing values of X_per and
       Fas_per on the fly would be more efficient than storing them
       (it would certainly take way less memory)
	 - [ ] Major redundancy with Y, Yc, Yc_tilde.
	 - [ ] Look into using the FMM on Y and Yc/Yc_tilde separately to
       avoid the overhead of sorting.
	 - [ ] Look into going back to -1's instead of
       boost::optional... Only problem here, though, is that if we
       want to support unsigned ints, this will be problematic.
	   - [ ] In order to support unsigned types, we could encode "not
         there" as a nonsense value---i.e. if we require first <=
         second, then choosing some value (e.g. (1, 0)) s.t. first >
         second would encode "not there".
**** Future optimizations
	 - [ ] Compute checkpoint FMM directly if there are few enough checkpoints?
	 - [ ] We could also use a different FMM (i.e. in terms of
       truncation number and level) for the checkpoints. Since they
       are more sparsely distributed, we may want to use a shallower
       FMM...?
**** Eventually
   	 - [ ] parallelize
	   - OpenMP?
	   - C++11 threads?
	   - TBB?
**** Things to try autotuning
   	 - [ ] Whether or not functions are inline
   	 - [ ] Duff's device for loop unrolling (this can be done using
       TMP--Game Programming Gems (maybe #1) books has a good
       tutorial).
   	 - [ ] Loop tiling
